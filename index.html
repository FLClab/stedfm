<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>STED-FM</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <nav class="navbar">
        <ul class="nav-links">
            <li><a href="#home">Home</a></li>
            <li><a href="https://www.biorxiv.org/content/10.1101/2025.06.06.656993v1">Paper</a></li>
            <li><a href="https://github.com/FLClab/STED-FM"><img src="images/github-mark/github-mark-white.png" alt="GitHub" style="width: 20px; height: 20px; margin-bottom: 4px; vertical-align: middle;"> Code</a></li>
        </ul>
    </nav>
    <div class="banner">
        <img src="images/neuron.png" alt="Neuron Banner">
        <div class="banner-content">
            <h1>STED-FM</h1>
            <span>A Self-Supervised Foundation Model for Robust and Generalizable Representation Learning in STED Microscopy</span>
        </div>
    </div>
    <div class="results">
        <img src="images/figure1_v5.png" alt="Figure 1">
        <div class="abstract">
            <span class="abstract-title">Abstract</span>
            <span class="abstract-body">Foundation Models (FMs) have dramatically increased the potential and power of deep learning algorithms in the fields of natural language processing and computer vision. However, their application in specialized fields like biomedical imaging and fluorescence microscopy remains difficult due to distribution shifts and the scarcity of high-quality annotated datasets. The high cost of data acquisition and the requirement for in-domain expertise further exacerbate this challenge in super-resolution microscopy. To address this we introduce STED-FM, a foundation model specifically designed for super-resolution STimulated Emission Depletion (STED) microscopy. STED-FM leverages a Vision Transformer architecture trained at scale with Masked Autoencoding on a new dataset of nearly one million STED images. STED-FM learns expressive latent representations without extensive annotations, leading to robust performance across diverse downstream microscopy image analysis tasks. Unsupervised experiments highlight the discriminative nature of its learned latent space. Our model significantly reduces the need for annotated data required to achieve strong performance in classification and segmentation tasks, both in- and out-of-distribution. Beyond its core capabilities, STED-FM enhances the quality of images generated by diffusion models, enabling latent attribute manipulation for the data-driven discovery of novel and subtle nanostructures and phenotypes. Moreover, its powerful structure retrieval capabilities are integrated into automated STED microscopy acquisition pipelines, paving the way for smart microscopy. In sum, we demonstrate that STED-FM lays a robust foundation for state-of-the-art algorithms across a wide array of tasks, establishing it as a highly valuable and scalable resource for researchers in super-resolution microscopy.</span> 
        </div>
    </div>

    <div class="datasets">
        <h1>Datasets</h1>
        <ul class="dataset-list">
            <li class="dataset-item">
                <h2>STED-FM full dataset</h2>
                <p>The large-scale collection of STED microscopy image crops pre-processed into a single .tar file. This is the dataset used for training STED-FM.</p>
                <a href="http://s3.valeria.science/flclab-foundation-models/data/STED-FM-dataset-crops.zip" target="_blank">Download Dataset</a>
            </li>
            <li class="dataset-item">
                <h2>Raw STED-FM npz dataset</h2>
                <p>Raw STED-FM dataset with every crop in npz format with original pixel count values.</p>
                <a href="http://s3.valeria.science/flclab-foundation-models/data/STED-FM-dataset-crops-raw.zip" target="_blank">Download Dataset</a>
            </li>
            <li class="dataset-item">
                <h2>Raw STED-FM tiff dataset</h2>
                <p>Raw STED-FM dataset with every crop in tiff format with original pixel count values.</p>
                <a href="http://s3.valeria.science/flclab-foundation-models/data/STED-FM-dataset-crops-tiff-raw.zip" target="_blank">Download Dataset</a>
            </li>
            <li class="dataset-item">
                <h2>STED-FM annotated subet</h2>
                <p>Subset of the STED-FM dataset with labels identifying the protein imaged. Pre-processed into a single .tar file.</p>
                <a href="http://s3.valeria.science/flclab-foundation-models/data/STED-FM-subset-dataset-crops.zip" target="_blank">Download Dataset</a>
            </li>
            <li class="dataset-item">
                <h2>Raw STED-FM npz subset</h2>
                <p>Raw STED-FM subset with every crop in npz format with original pixel count values.</p>
                <a href="http://s3.valeria.science/flclab-foundation-models/data/STED-FM-subset-dataset-crops-raw.zip" target="_blank">Download Dataset</a>
            </li>
            <li class="dataset-item">
                <h2>Raw STED-FM tiff subset</h2>
                <p>Raw STED-FM subset with every crop in tiff format with original pixel count values.</p>
                <a href="http://s3.valeria.science/flclab-foundation-models/data/STED-FM-subset-dataset-crops-tiff-raw.zip" target="_blank">Download Dataset</a>
            </li>
        </ul>
    </div>

</body>
</html> 