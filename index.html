<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>STED-FM</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <nav class="navbar">
        <ul class="nav-links">
            <li><a href="#home">Home</a></li>
            <li><a href="#paper">Paper</a></li>
            <li><a href="https://github.com/FLClab/STED-FM"><img src="images/github-mark/github-mark-white.png" alt="GitHub" style="width: 20px; height: 20px; margin-bottom: 4px; vertical-align: middle;"> Code</a></li>
        </ul>
    </nav>
    <div class="banner">
        <img src="images/neuron.png" alt="Neuron Banner">
        <div class="banner-content">
            <h1>STED-FM</h1>
            <span>A Self-Supervised Foundation Model for Robust and Generalizable Representation Learning in STED Microscopy</span>
        </div>
    </div>
    <div class="results">
        <img src="images/figure1_v5.png" alt="Figure 1">
        <div class="abstract">
            <span class="abstract-title">Abstract</span>
            <span class="abstract-body">Foundation Models (FMs) have dramatically increased the potential and power of deep learning algorithms in the fields of natural language processing and computer vision. However, their application in specialized fields like biomedical imaging and fluorescence microscopy remains difficult due to distribution shifts and the scarcity of high-quality annotated datasets. The high cost of data acquisition and the requirement for in-domain expertise further exacerbate this challenge in super-resolution microscopy. To address this we introduce STED-FM, a foundation model specifically designed for super-resolution STimulated Emission Depletion (STED) microscopy. STED-FM leverages a Vision Transformer architecture trained at scale with Masked Autoencoding on a new dataset of nearly one million STED images. STED-FM learns expressive latent representations without extensive annotations, leading to robust performance across diverse downstream microscopy image analysis tasks. Unsupervised experiments highlight the discriminative nature of its learned latent space. Our model significantly reduces the need for annotated data required to achieve strong performance in classification and segmentation tasks, both in- and out-of-distribution. Beyond its core capabilities, STED-FM enhances the quality of images generated by diffusion models, enabling latent attribute manipulation for the data-driven discovery of novel and subtle nanostructures and phenotypes. Moreover, its powerful structure retrieval capabilities are integrated into automated STED microscopy acquisition pipelines, paving the way for smart microscopy. In sum, we demonstrate that STED-FM lays a robust foundation for state-of-the-art algorithms across a wide array of tasks, establishing it as a highly valuable and scalable resource for researchers in super-resolution microscopy.</span> 
        </div>
    </div>

</body>
</html> 